name: Incremental Index on Merge

on:
  push:
    branches: [ main ]
    paths:
      - '**.py'
      - '**.ts'
      - '**.tsx'
      - '**.js'
      - '**.jsx'
  workflow_dispatch:
    inputs:
      force_full_index:
        description: 'Force full index instead of incremental'
        required: false
        default: 'false'
        type: boolean

jobs:
  incremental-index:
    runs-on: ubuntu-latest
    if: github.repository == 'ai-cherry/sophia-ai-intel'
    
    environment: production
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for git analysis
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential
    
    - name: Install Python dependencies
      working-directory: services/mcp-context
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install tree-sitter-python tree-sitter-typescript tree-sitter-javascript
        pip install openai asyncpg
    
    - name: Wait for Context MCP service
      run: |
        echo "Waiting for Context MCP service to be available..."
        timeout=300
        while [ $timeout -gt 0 ]; do
          if curl -f -s "https://sophiaai-mcp-context-v2.fly.dev/healthz" > /dev/null 2>&1; then
            echo "✓ Context MCP service is healthy"
            break
          fi
          echo "Waiting for service... ($timeout seconds remaining)"
          sleep 10
          timeout=$((timeout - 10))
        done
        
        if [ $timeout -le 0 ]; then
          echo "❌ Context MCP service not available after 5 minutes"
          exit 1
        fi
    
    - name: Check if full index needed
      id: check_index_type
      run: |
        INDEX_TYPE="incremental"
        
        # Force full if requested
        if [ "${{ github.event.inputs.force_full_index }}" = "true" ]; then
          INDEX_TYPE="full"
          echo "Full index forced via workflow dispatch"
        fi
        
        # Check if this is first index (no previous index statistics)
        # This would require database connection to check properly
        # For now, default to incremental
        
        echo "index_type=$INDEX_TYPE" >> $GITHUB_OUTPUT
        echo "Using index type: $INDEX_TYPE"
    
    - name: Run symbol indexer
      working-directory: services/mcp-context
      env:
        DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        python symbol_indexer.py \
          --project-root "../../" \
          --project-name "sophia-ai-intel" \
          --db-url "$DATABASE_URL" \
          --openai-api-key "$OPENAI_API_KEY" \
          --index-type "${{ steps.check_index_type.outputs.index_type }}" \
        | tee index_output.log
    
    - name: Generate index proof
      run: |
        # Extract statistics from indexer output
        FILES_PROCESSED=$(grep "Files processed:" services/mcp-context/index_output.log | cut -d: -f2 | xargs || echo "0")
        SYMBOLS_EXTRACTED=$(grep "Symbols extracted:" services/mcp-context/index_output.log | cut -d: -f2 | xargs || echo "0")
        PROCESSING_TIME=$(grep "Processing time:" services/mcp-context/index_output.log | cut -d: -f2 | sed 's/ms//' | xargs || echo "0")
        ERRORS_COUNT=$(grep "Errors:" services/mcp-context/index_output.log | cut -d: -f2 | xargs || echo "0")
        
        # Generate proof JSON
        cat > proofs/context/index_on_merge_$(date +%Y%m%d_%H%M%S).json << EOF
        {
          "status": "success",
          "query": "Incremental code indexing on merge to main",
          "results": [
            {
              "index_type": "${{ steps.check_index_type.outputs.index_type }}",
              "project": "sophia-ai-intel",
              "files_processed": $FILES_PROCESSED,
              "symbols_extracted": $SYMBOLS_EXTRACTED,
              "processing_time_ms": $PROCESSING_TIME,
              "errors_encountered": $ERRORS_COUNT,
              "git_commit": "${{ github.sha }}",
              "triggered_by": "${{ github.event_name }}"
            }
          ],
          "summary": {
            "text": "Code symbols indexed successfully with tree-sitter parsing and OpenAI embeddings",
            "confidence": 1.0,
            "model": "symbol_indexer",
            "sources": ["tree-sitter", "openai-embeddings", "neon-postgresql"]
          },
          "infrastructure": {
            "database": "neon-postgresql",
            "embeddings": "openai-text-embedding-3-small",
            "dimensions": 1536,
            "languages_supported": ["python", "typescript", "javascript"]
          },
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "execution_time_ms": $PROCESSING_TIME,
          "errors": []
        }
        EOF
        
        echo "Generated index proof with $SYMBOLS_EXTRACTED symbols from $FILES_PROCESSED files"
    
    - name: Commit index proof
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add proofs/context/
        if git diff --cached --quiet; then
          echo "No changes to commit"
        else
          git commit -m "[auto] Index proof: ${{ steps.check_index_type.outputs.index_type }} indexing completed"
          git push
        fi
    
    - name: Update Context MCP cache
      run: |
        # Trigger cache refresh on Context MCP service
        curl -X POST "https://sophiaai-mcp-context-v2.fly.dev/internal/refresh-cache" \
          -H "Content-Type: application/json" \
          -d '{"reason": "index_updated", "commit": "${{ github.sha }}"}' \
          || echo "⚠️ Could not refresh Context MCP cache (service may not support this endpoint yet)"
    
    - name: Verify indexing results
      working-directory: services/mcp-context
      env:
        DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
      run: |
        # Simple verification query
        python3 -c "
        import asyncio
        import asyncpg
        import os
        
        async def verify():
            conn = await asyncpg.connect(os.environ['DATABASE_URL'])
            
            # Get project stats
            project_stats = await conn.fetchrow('''
                SELECT 
                    COUNT(s.id) as total_symbols,
                    COUNT(DISTINCT s.file_path) as files_with_symbols,
                    COUNT(DISTINCT s.language) as languages,
                    MAX(s.last_modified) as last_updated
                FROM projects p
                LEFT JOIN symbols s ON p.id = s.project_id
                WHERE p.name = \$1
                GROUP BY p.id
            ''', 'sophia-ai-intel')
            
            if project_stats:
                print(f'✓ Verification: {project_stats[\"total_symbols\"]} symbols across {project_stats[\"files_with_symbols\"]} files in {project_stats[\"languages\"]} languages')
                print(f'✓ Last updated: {project_stats[\"last_updated\"]}')
            else:
                print('⚠️ No indexing statistics found')
            
            await conn.close()
        
        asyncio.run(verify())
        " || echo "⚠️ Verification failed (database may not be accessible)"

  notify-completion:
    needs: incremental-index
    runs-on: ubuntu-latest
    if: always() && github.repository == 'ai-cherry/sophia-ai-intel'
    
    steps:
    - name: Notify indexing completion
      run: |
        if [ "${{ needs.incremental-index.result }}" = "success" ]; then
          echo "✅ Incremental indexing completed successfully"
          # Could send notification to Telegram via Business MCP here
        else
          echo "❌ Incremental indexing failed"
          # Could send error notification here
        fi