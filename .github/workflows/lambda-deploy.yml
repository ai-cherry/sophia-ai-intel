name: Deploy to Lambda Labs - Automated

on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      instance_type:
        description: "Lambda Labs instance type"
        required: false
        default: "gpu_1x_a100_sxm4"
        type: choice
        options:
          - gpu_1x_a100_sxm4
          - gpu_1x_h100_pcie
          - gpu_8x_a100_80gb_sxm4

permissions:
  contents: read

env:
  PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}

jobs:
  deploy-to-lambda-labs:
    name: Deploy Sophia AI to Lambda Labs
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Setup Pulumi
        uses: pulumi/actions@v4
        with:
          pulumi-version: latest
      
      - name: Install Python dependencies
        run: |
          cd ops/pulumi
          pip install -r requirements.txt
      
      - name: Configure Pulumi secrets
        working-directory: ops/pulumi
        run: |
          # Select production stack
          pulumi stack select production --create
          
          # Core Lambda Labs configuration
          pulumi config set --secret lambda-api-key "${{ secrets.LAMBDA_API_KEY }}"
          
          # Core application secrets
          pulumi config set --secret openai-api-key "${{ secrets.OPENAI_API_KEY }}"
          pulumi config set --secret neon-database-url "${{ secrets.NEON_REST_API_ENDPOINT }}"
          pulumi config set --secret redis-url "redis://default:${{ secrets.REDIS_USER_KEY }}@${{ secrets.REDIS_HOST }}:${{ secrets.REDIS_PORT }}"
          
          # Research APIs
          pulumi config set --secret tavily-api-key "${{ secrets.TAVILY_API_KEY }}"
          pulumi config set --secret perplexity-api-key "${{ secrets.PERPLEXITY_API_KEY }}"
          pulumi config set --secret anthropic-api-key "${{ secrets.ANTHROPIC_API_KEY }}"
          pulumi config set --secret serper-api-key "${{ secrets.SERPER_API_KEY }}"
          
          # Vector database
          pulumi config set --secret qdrant-api-key "${{ secrets.QDRANT_API_KEY }}"
          pulumi config set --secret qdrant-url "${{ secrets.QDRANT_URL }}"
          
          # Business APIs
          pulumi config set --secret hubspot-access-token "${{ secrets.HUBSPOT_API_TOKEN }}"
          pulumi config set --secret apollo-api-key "${{ secrets.APOLLO_IO_API_KEY }}"
          
          # Optional providers
          pulumi config set --secret groq-api-key "${{ secrets.GROQ_API_KEY }}"
          pulumi config set --secret deepseek-api-key "${{ secrets.DEEPSEEK_API_KEY }}"
          pulumi config set --secret mistral-api-key "${{ secrets.MISTRAL_API_KEY }}"
          
          # Instance configuration
          pulumi config set instance-type "${{ github.event.inputs.instance_type || 'gpu_1x_a100_sxm4' }}"
      
      - name: Deploy to Lambda Labs
        working-directory: ops/pulumi
        run: |
          echo "ðŸš€ Deploying Sophia AI to Lambda Labs..."
          pulumi up --yes
          echo "âœ… Deployment completed!"
      
      - name: Get deployment outputs
        working-directory: ops/pulumi
        run: |
          echo "ðŸ“Š Deployment Information:"
          pulumi stack output --json > deployment-outputs.json
          
          # Extract key URLs
          INSTANCE_IP=$(pulumi stack output instance_ip 2>/dev/null || echo "pending")
          
          if [ "$INSTANCE_IP" != "pending" ]; then
            echo "ðŸŒ YOUR LIVE PLATFORM:"
            echo "Dashboard: http://$INSTANCE_IP:3000"
            echo "Research API: http://$INSTANCE_IP:8081"
            echo "Context API: http://$INSTANCE_IP:8082"
            echo "GitHub API: http://$INSTANCE_IP:8083"
            echo "Business API: http://$INSTANCE_IP:8084"
            echo "Lambda API: http://$INSTANCE_IP:8085"
            echo "HubSpot API: http://$INSTANCE_IP:8086"
            echo ""
            echo "ðŸ”§ Management:"
            echo "SSH: ssh ubuntu@$INSTANCE_IP"
            echo "Logs: docker-compose logs -f"
          else
            echo "â³ Instance still provisioning..."
          fi
      
      - name: Create deployment summary
        working-directory: ops/pulumi
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          INSTANCE_IP=$(pulumi stack output instance_ip 2>/dev/null || echo "pending")
          
          cat > deployment-summary.md << EOF
          # ðŸš€ Sophia AI Intel - Lambda Labs Deployment
          
          **Deployment Date**: $TIMESTAMP
          **Commit**: ${{ github.sha }}
          **Instance Type**: ${{ github.event.inputs.instance_type || 'gpu_1x_a100_sxm4' }}
          **Lambda Labs IP**: $INSTANCE_IP
          
          ## ðŸŒ Live Platform URLs
          
          - **Dashboard**: http://$INSTANCE_IP:3000
          - **Research API**: http://$INSTANCE_IP:8081
          - **Context API**: http://$INSTANCE_IP:8082
          - **GitHub API**: http://$INSTANCE_IP:8083
          - **Business API**: http://$INSTANCE_IP:8084
          - **Lambda API**: http://$INSTANCE_IP:8085
          - **HubSpot API**: http://$INSTANCE_IP:8086
          
          ## ðŸ”§ Management
          
          - **SSH**: ssh ubuntu@$INSTANCE_IP
          - **Logs**: docker-compose logs -f
          - **Restart**: docker-compose restart
          
          ## âœ… Status: DEPLOYED ON LAMBDA LABS GPU
          EOF
          
          cat deployment-summary.md
      
      - name: Archive deployment info
        uses: actions/upload-artifact@v4
        with:
          name: lambda-labs-deployment-${{ github.run_id }}
          path: |
            ops/pulumi/deployment-outputs.json
            ops/pulumi/deployment-summary.md
          retention-days: 30
      
      - name: Deployment complete notification
        run: |
          echo "ðŸŽ‰ SOPHIA AI INTEL DEPLOYED SUCCESSFULLY!"
          echo ""
          echo "âœ… Platform running on Lambda Labs GPU"
          echo "âœ… All microservices deployed via Docker"
          echo "âœ… Zero local dependencies"
          echo "âœ… Production-ready on GPU infrastructure"
          echo ""
          echo "ðŸŒŸ Your deployment nightmare is OVER!"
